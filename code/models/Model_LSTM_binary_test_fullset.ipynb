{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary LSTM classification model\n",
    "## Trained on older feed (Sept), inferred on latest feed (Nov)\n",
    "\n",
    "** This notebook trains the Binary classification model on an older (Sept'18) High Confidence (HC) DGA feed and then does the inference on a more recent feed, from Nov'18.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing import text\n",
    "\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11208480337296706510\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2384576512\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 662418254486582015\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Check if gpu can be utilized for acceleration\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DGA and Cisco high confidence data\n",
    "\n",
    "dga_df = pd.read_csv('..\\\\data\\\\2018_0923\\\\dga-feed-high.csv', header=None, skiprows=15)\n",
    "cisco_df = pd.read_csv('..\\\\data\\\\2018_0923\\\\top-1m.csv', header=None)\n",
    "dga_new_df = pd.read_csv('..\\\\data\\\\2018-11-12\\\\dga-feed-high.csv', header=None, skiprows=15)\n",
    "\n",
    "# Path and file variables for saving model information\n",
    "path_dir = '.\\\\saved_models\\\\trainOld_inferNew\\\\'\n",
    "name_encoder      = path_dir + 'binary_tokenizer.pkl'\n",
    "name_model        = path_dir + 'binary_LSTM.json'\n",
    "name_weights      = path_dir + 'binary_LSTM.h5'\n",
    "name_categories   = path_dir + 'binary_categories.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display head\n",
    "def display_df(dga_df_, cisco_df_, dga_all_df_):\n",
    "    display(\"DGA feed sample: {}\".format( dga_df_.shape) )\n",
    "    display(dga_df_.head())\n",
    "    display(\"DGA feed high and low confidence sample: {}\".format( dga_all_df_.shape))\n",
    "    display(dga_all_df_.head())\n",
    "    display(\"Cisco feed sample: {}\".format( cisco_df_.shape) )\n",
    "    display(cisco_df_.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused columns, add output label 'dga'\n",
    "\n",
    "dga_df_slim =   dga_df.drop(columns=range(1,dga_df.shape[1]), inplace=False)\n",
    "dga_df_slim.columns = ['domain']\n",
    "dga_new_df_slim =   dga_new_df.drop(columns=range(1,dga_new_df.shape[1]), inplace=False)\n",
    "dga_new_df_slim.columns = ['domain']\n",
    "\n",
    "cisco_df_slim = cisco_df.drop(columns=[0], inplace=False)\n",
    "cisco_df_slim.columns = ['domain']\n",
    "dga_df_slim['dga'] = 1\n",
    "dga_new_df_slim['dga'] = 1\n",
    "cisco_df_slim['dga'] = 0\n",
    "\n",
    "#display_df(dga_df_slim, cisco_df_slim, dga_all_df_slim)\n",
    "unified_df = pd.concat([cisco_df_slim, dga_df_slim], ignore_index=True)\n",
    "unified_df['dga'], labels = pd.factorize(unified_df['dga'], sort=True)   # binary factorization and potentially realigning the DGA categories\n",
    "with open(name_categories, 'wb') as catEnc:\n",
    "    pickle.dump(labels, catEnc, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input sequences (domains) and output labels (DGA 0/1), and do train/test split\n",
    "\n",
    "X_train = unified_df['domain']\n",
    "Y_train = unified_df['dga']\n",
    "X_test  = dga_new_df_slim['domain']\n",
    "Y_test  = dga_new_df_slim['dga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1381953/1381953 [==============================] - 1630s 1ms/step - loss: 0.0609\n"
     ]
    }
   ],
   "source": [
    "# Binary classification LSTM model\n",
    "\n",
    "TRAIN_MODEL = True                                          # Load saved model otherwise\n",
    "max_features = 1000                                          # length of vocabulary\n",
    "batch_size = 128                                             # input batch size\n",
    "num_epochs = 1                                               # epochs to train\n",
    "    \n",
    "if TRAIN_MODEL != True:\n",
    "    file = open(name_model, 'r')\n",
    "    model_load = file.read()\n",
    "    file.close()\n",
    "    model = model_from_json(model_load)\n",
    "    model.load_weights(name_weights)\n",
    "    with open(name_tokenizer, 'rb') as tokenEnc:\n",
    "        encoder = pickle.load(tokenEnc)\n",
    "    with open(name_categories, 'rb') as catEnc:\n",
    "        labels = pickle.load(catEnc)\n",
    "    print('MODEL TRAINING SKIPPED.\\nSAVED MODEL IS NOW LOADED!')\n",
    "\n",
    "else:                                                        # train the model\n",
    "    # encode string characters to integers\n",
    "    encoder = text.Tokenizer(num_words=500, char_level=True)\n",
    "    encoder.fit_on_texts(X_train)                            # build character indices\n",
    "    X_train_tz = encoder.texts_to_sequences(X_train)\n",
    "    \n",
    "    # Model definition - this is the core model from Endgame\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(max_features, 128, input_length=75))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    # Pad sequence where sequences are case insensitive characters encoded to\n",
    "    # integers from 0 to number of valid characters\n",
    "    X_train_pad=sequence.pad_sequences(X_train_tz, maxlen=75)\n",
    "    \n",
    "    # Train where Y_train is 0-1\n",
    "    model.fit(X_train_pad, Y_train, batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on new DGA feed =   97.887 %\n"
     ]
    }
   ],
   "source": [
    "# Validation on test dataset\n",
    "\n",
    "X_test_pad = sequence.pad_sequences(encoder.texts_to_sequences(X_test), maxlen=75)\n",
    "Y_pred = model.predict_classes(X_test_pad)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Model accuracy on new DGA feed = {:8.3f} %\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skipping the model's prediction probability retrieval in this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SAVED TO DISK!\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if TRAIN_MODEL == True:\n",
    "    model_save = model.to_json()\n",
    "    with open(name_model, 'w') as file:\n",
    "        file.write(model_save)\n",
    "    model.save_weights(name_weights)\n",
    "    with open(name_encoder, 'wb') as tokenEnc:\n",
    "        pickle.dump(encoder, tokenEnc, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('MODEL SAVED TO DISK!')\n",
    "else:\n",
    "    print('MODEL AREADY SAVED TO DISK.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
